{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c797e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23b098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the database\n",
    "url_share = \"https://docs.google.com/spreadsheets/d/1UQsU6FNr7ovVjLRIMIt\"\\\n",
    "            \"gtYWr1zN7UHpMjfHtdGa1myc/edit#gid=0\"\n",
    "url_csv = url_share.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "df = pd.read_csv(url_csv, sep = ',', na_filter = True)\n",
    "\n",
    "# Manage the empty boxes\n",
    "df.fillna(value = 'None', inplace = True)\n",
    "\n",
    "# Create a list of the subjects and a reference path for the results\n",
    "subjects = ['Sub01', 'Sub02', 'Sub03', 'Sub04', 'Sub05', 'Sub06']\n",
    "parent_path = '../results/BIDS_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788343f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the subject-level folders exist\n",
    "# If not, create them\n",
    "\n",
    "def create_folder_subjects(subject, parent_path):\n",
    "    dir_content = os.listdir(parent_path)\n",
    "    dir_content.sort()\n",
    "    sub_ID = subject.lstrip(\"Sub\")\n",
    "    if dir_content.count(f\"sub-{sub_ID}\") == 1:\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(f\"{parent_path}sub-{sub_ID}\")\n",
    "        #print(f\"created the \\\"sub-{sub_ID}\\\" folder in {parent_path}\")\n",
    "\n",
    "for i in subjects:\n",
    "    create_folder_subjects(i, parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8adcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single participant sub-df extraction\n",
    "\n",
    "def subject_extractor(df, subject_ID):\n",
    "    mask = df['Participant_ID'] == subject_ID\n",
    "    sub_df = df[mask].reset_index(drop=True)\n",
    "    \n",
    "    return sub_df\n",
    "\n",
    "data_sub01 = subject_extractor(df, 'Sub01')\n",
    "data_sub02 = subject_extractor(df, 'Sub02')\n",
    "data_sub03 = subject_extractor(df, 'Sub03')\n",
    "data_sub04 = subject_extractor(df, 'Sub04')\n",
    "data_sub05 = subject_extractor(df, 'Sub05')\n",
    "data_sub06 = subject_extractor(df, 'Sub06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97261ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the session-level folders exist for each participant\n",
    "# If not, create them\n",
    "\n",
    "def create_folder_session(subject, session_count):\n",
    "    sub_ID = subject.lstrip(\"Sub\")\n",
    "    children_path = f\"{parent_path}sub-{sub_ID}/\"\n",
    "    dir_content = os.listdir(children_path)\n",
    "    for j in range(1, session_count + 1):\n",
    "        if dir_content.count(f\"ses-{j:02d}\") == 1:\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir(f\"{children_path}ses-{j:02d}\")\n",
    "            #print(f\"created the \\\"ses-{j:02d}\\\" folder in {children_path}\")            \n",
    "\n",
    "for i in subjects:\n",
    "    create_folder_session(i, len(globals()[f\"data_{i.lower()}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "615d66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to be used for each test\n",
    "\n",
    "# Subject and session settings data\n",
    "columns_conditions = ['Participant_ID', 'DATE',\n",
    "                      'Protocol name', 'Protocol condition',\n",
    "                      'Scan type']\n",
    "\n",
    "# Generate the column titles to be used in the tsv files\n",
    "x_tymp = ['Type', 'TPP', 'ECV', 'SC', 'TW']\n",
    "x_reflex = [500, 1000, 2000, 4000, 'NOISE']\n",
    "x_PTA = [250, 500, 1000, 2000, 3000, 4000, 6000, 8000,\n",
    "         9000, 10000, 11200, 12500, 14000, 16000, 18000, 20000]\n",
    "x_MTX = ['LANGUAGE', \"Practice\", \"Sp_Bin_No_Bin\",\n",
    "         \"Sp_L_No_Bin\", \"Sp_R_No_Bin\", \"Sp_L_No_L\",  \"Sp_R_No_R\"]\n",
    "\n",
    "# Initialize empty lists to be filed with the proper column titles for each test\n",
    "columns_tymp = []\n",
    "columns_tymp_R = []\n",
    "columns_tymp_L = []\n",
    "\n",
    "columns_reflex = []\n",
    "columns_reflex_R = []\n",
    "columns_reflex_L = []\n",
    "\n",
    "columns_PTA = []\n",
    "columns_PTA_R = []\n",
    "columns_PTA_L = []\n",
    "\n",
    "columns_MTX = []\n",
    "columns_MTX_L1 = []\n",
    "columns_MTX_L2 = []\n",
    "\n",
    "# Generate column title lists to be able to extract the data for each test\n",
    "for i in df.columns:\n",
    "    if i.endswith(\"_RE\") is True:\n",
    "        columns_tymp.append(i)\n",
    "        columns_tymp_R.append(i)\n",
    "    elif i.endswith(\"_LE\") is True:\n",
    "        columns_tymp.append(i)\n",
    "        columns_tymp_L.append(i)\n",
    "    elif i.startswith(\"REFLEX_RE_\") is True:\n",
    "        columns_reflex.append(i)\n",
    "        columns_reflex_R.append(i)\n",
    "    elif i.startswith(\"REFLEX_LE_\") is True:\n",
    "        columns_reflex.append(i)\n",
    "        columns_reflex_L.append(i)\n",
    "    elif i.startswith(\"RE_\") is True:\n",
    "        columns_PTA.append(i)\n",
    "        columns_PTA_R.append(i)\n",
    "    elif i.startswith(\"LE_\") is True:\n",
    "        columns_PTA.append(i)\n",
    "        columns_PTA_L.append(i)\n",
    "    elif i.startswith(\"MTX1\") is True:\n",
    "        columns_MTX.append(i)\n",
    "        columns_MTX_L1.append(i)\n",
    "    elif i.startswith(\"MTX2\") is True:\n",
    "        columns_MTX.append(i)\n",
    "        columns_MTX_L2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec22a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single test sub-df extraction from each participant's sub-df\n",
    "\n",
    "def eliminate_columns(sub_df, data_columns, test_columns):\n",
    "    to_keep = data_columns + test_columns\n",
    "    df_test = sub_df[to_keep]    \n",
    "    return df_test\n",
    "\n",
    "tymp_sub01 = eliminate_columns(data_sub01, columns_conditions, columns_tymp)\n",
    "tymp_sub02 = eliminate_columns(data_sub02, columns_conditions, columns_tymp)\n",
    "tymp_sub03 = eliminate_columns(data_sub03, columns_conditions, columns_tymp)\n",
    "tymp_sub04 = eliminate_columns(data_sub04, columns_conditions, columns_tymp)\n",
    "tymp_sub05 = eliminate_columns(data_sub05, columns_conditions, columns_tymp)\n",
    "tymp_sub06 = eliminate_columns(data_sub06, columns_conditions, columns_tymp)\n",
    "\n",
    "reflex_sub01 = eliminate_columns(data_sub01, columns_conditions, columns_reflex)\n",
    "reflex_sub02 = eliminate_columns(data_sub02, columns_conditions, columns_reflex)\n",
    "reflex_sub03 = eliminate_columns(data_sub03, columns_conditions, columns_reflex)\n",
    "reflex_sub04 = eliminate_columns(data_sub04, columns_conditions, columns_reflex)\n",
    "reflex_sub05 = eliminate_columns(data_sub05, columns_conditions, columns_reflex)\n",
    "reflex_sub06 = eliminate_columns(data_sub06, columns_conditions, columns_reflex)\n",
    "\n",
    "pta_sub01 = eliminate_columns(data_sub01, columns_conditions, columns_PTA)\n",
    "pta_sub02 = eliminate_columns(data_sub02, columns_conditions, columns_PTA)\n",
    "pta_sub03 = eliminate_columns(data_sub03, columns_conditions, columns_PTA)\n",
    "pta_sub04 = eliminate_columns(data_sub04, columns_conditions, columns_PTA)\n",
    "pta_sub05 = eliminate_columns(data_sub05, columns_conditions, columns_PTA)\n",
    "pta_sub06 = eliminate_columns(data_sub06, columns_conditions, columns_PTA)\n",
    "\n",
    "mtx_sub01 = eliminate_columns(data_sub01, columns_conditions, columns_MTX)\n",
    "mtx_sub02 = eliminate_columns(data_sub02, columns_conditions, columns_MTX)\n",
    "mtx_sub03 = eliminate_columns(data_sub03, columns_conditions, columns_MTX)\n",
    "mtx_sub04 = eliminate_columns(data_sub04, columns_conditions, columns_MTX)\n",
    "mtx_sub05 = eliminate_columns(data_sub05, columns_conditions, columns_MTX)\n",
    "mtx_sub06 = eliminate_columns(data_sub06, columns_conditions, columns_MTX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20ad382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to save the tsv files\n",
    "# This function is called by the following functions and saves the data they provide with the specified path\n",
    "\n",
    "def save_df(data_tosave_df, single_test_df, index, test, run):\n",
    "    sub = single_test_df['Participant_ID'][index].lstrip('Sub_')\n",
    "\n",
    "    if (index + 1) < 10:\n",
    "        ses = '0' + str(index + 1)\n",
    "    else:\n",
    "        ses = str(index + 1)\n",
    "        \n",
    "    ext = '.tsv'    # can be replaced with \".csv\". The last cell must then be activated\n",
    "    \n",
    "    path = parent_path + 'sub-' + sub + '/' + 'ses-' + ses + '/'\n",
    "    file_name = 'sub-' + sub + '_ses-' + ses + '_task-' + test + '_run-' + run + ext\n",
    "    \n",
    "    data_tosave_df.to_csv(path + file_name, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777dc879",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extraction of every single tympanometry test\n",
    "# The results are then sent to the save_df function to be saved\n",
    "\n",
    "def extract_tymp(single_test_df, ls_columns):\n",
    "    x = x_tymp\n",
    "    \n",
    "    for j in range(0, len(single_test_df)):\n",
    "        \n",
    "        y = [[]]\n",
    "        \n",
    "        for k in ls_columns:\n",
    "            y[0].append(single_test_df[k][j])\n",
    "            if ls_columns == columns_tymp_R:\n",
    "                run = '01'\n",
    "            elif ls_columns == columns_tymp_L:\n",
    "                run = '02'\n",
    "        \n",
    "        mask = []\n",
    "        \n",
    "        for m in range(0, len(y[0])):\n",
    "            if y[0][m] == 'None':\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "        \n",
    "        z = pd.DataFrame(data=y, columns=x)\n",
    "        \n",
    "        save_df(z, single_test_df, j, 'Tymp', run)\n",
    "        if False in mask:\n",
    "            save_df(z, single_test_df, j, 'Tymp', run)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "extract_tymp(tymp_sub01, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub01, columns_tymp_L)\n",
    "extract_tymp(tymp_sub02, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub02, columns_tymp_L)\n",
    "extract_tymp(tymp_sub03, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub03, columns_tymp_L)\n",
    "extract_tymp(tymp_sub04, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub04, columns_tymp_L)\n",
    "extract_tymp(tymp_sub05, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub05, columns_tymp_L)\n",
    "extract_tymp(tymp_sub06, columns_tymp_R)    \n",
    "extract_tymp(tymp_sub06, columns_tymp_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01ec049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of every single stapedial reflex test\n",
    "# The results are then sent to the save_df function to be saved\n",
    "\n",
    "def extract_reflex(single_test_df, ls_columns):\n",
    "    x = x_reflex\n",
    "    \n",
    "    for j in range(0, len(single_test_df)):\n",
    "        y = [[]]\n",
    "        for k in ls_columns:\n",
    "            y[0].append(single_test_df[k][j])\n",
    "            if ls_columns == columns_reflex_R:\n",
    "                run = '01'\n",
    "            elif ls_columns == columns_reflex_L:\n",
    "                run = '02'\n",
    "                \n",
    "        mask = []\n",
    "        \n",
    "        for m in range(0, len(y[0])):\n",
    "            if y[0][m] == 'None':\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "        \n",
    "        z = pd.DataFrame(data=y, columns=x)\n",
    "        \n",
    "        if False in mask:\n",
    "            save_df(z, single_test_df, j, 'Reflex', run)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "extract_reflex(reflex_sub01, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub01, columns_reflex_L)\n",
    "extract_reflex(reflex_sub02, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub02, columns_reflex_L)\n",
    "extract_reflex(reflex_sub03, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub03, columns_reflex_L)\n",
    "extract_reflex(reflex_sub04, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub04, columns_reflex_L)\n",
    "extract_reflex(reflex_sub05, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub05, columns_reflex_L)\n",
    "extract_reflex(reflex_sub06, columns_reflex_R)    \n",
    "extract_reflex(reflex_sub06, columns_reflex_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6f550e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extraction of every single pure-tone audiometry test\n",
    "# The results are then sent to the save_df function to be saved\n",
    "\n",
    "def extract_pta(single_test_df, ls_columns):\n",
    "    x = x_PTA\n",
    "    \n",
    "    for j in range(0, len(single_test_df)):\n",
    "        y = [[]]\n",
    "        for k in ls_columns:\n",
    "            y[0].append(single_test_df[k][j])\n",
    "            if ls_columns == columns_PTA_R:\n",
    "                run = '01'\n",
    "            elif ls_columns == columns_PTA_L:\n",
    "                run = '02'\n",
    "                \n",
    "        mask = []\n",
    "        \n",
    "        for m in range(0, len(y[0])):\n",
    "            if y[0][m] == 'None':\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "        \n",
    "        z = pd.DataFrame(data=y, columns=x)\n",
    "        \n",
    "        if False in mask:\n",
    "            z.replace(to_replace=130, value=\"None\", inplace=True)\n",
    "            save_df(z, single_test_df, j, 'PTA', run)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "extract_pta(pta_sub01, columns_PTA_R)  \n",
    "extract_pta(pta_sub01, columns_PTA_L)\n",
    "extract_pta(pta_sub02, columns_PTA_R)  \n",
    "extract_pta(pta_sub02, columns_PTA_L)\n",
    "extract_pta(pta_sub03, columns_PTA_R)  \n",
    "extract_pta(pta_sub03, columns_PTA_L)\n",
    "extract_pta(pta_sub04, columns_PTA_R)  \n",
    "extract_pta(pta_sub04, columns_PTA_L)\n",
    "extract_pta(pta_sub05, columns_PTA_R)  \n",
    "extract_pta(pta_sub05, columns_PTA_L)\n",
    "extract_pta(pta_sub06, columns_PTA_R)  \n",
    "extract_pta(pta_sub06, columns_PTA_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7733bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of every single matrix speech-in-noise perception test\n",
    "# The results are then sent to the save_df function to be saved\n",
    "\n",
    "def extract_mtx(single_test_df, ls_columns):\n",
    "    x = x_MTX\n",
    "    \n",
    "    for j in range(0, len(single_test_df)):\n",
    "        y = [[]]\n",
    "        for k in ls_columns:\n",
    "            y[0].append(single_test_df[k][j])\n",
    "            if ls_columns == columns_MTX_L1:\n",
    "                run = '01'\n",
    "            elif ls_columns == columns_MTX_L2:\n",
    "                run = '02'\n",
    "                \n",
    "        mask = []\n",
    "        \n",
    "        for m in range(0, len(y[0])):\n",
    "            if y[0][m] == 'None':\n",
    "                mask.append(True)\n",
    "            else:\n",
    "                mask.append(False)\n",
    "        \n",
    "        z = pd.DataFrame(data=y, columns=x)\n",
    "        \n",
    "        if False in mask:\n",
    "            save_df(z, single_test_df, j, 'MTX', run)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "extract_mtx(mtx_sub01, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub01, columns_MTX_L2)\n",
    "extract_mtx(mtx_sub02, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub02, columns_MTX_L2)\n",
    "extract_mtx(mtx_sub03, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub03, columns_MTX_L2)\n",
    "extract_mtx(mtx_sub04, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub04, columns_MTX_L2)\n",
    "extract_mtx(mtx_sub05, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub05, columns_MTX_L2)\n",
    "extract_mtx(mtx_sub06, columns_MTX_L1)  \n",
    "extract_mtx(mtx_sub06, columns_MTX_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08ce20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is present if, for any reason, the .tsv files are not properly saved.\n",
    "# It is then possible to replace the variable \"ext\"'s value in the save_df function with \".csv\"\n",
    "# and run this cell to rename all the files with the correct \".tsv\" file extansion.\n",
    "\n",
    "#file_list = glob.glob(\"../results/BIDS_data/sub-*/ses-*/*.csv\")\n",
    "\n",
    "#for path in file_list:\n",
    "#    new_path = os.path.splitext(path)[0]+\".tsv\"\n",
    "#    os.system(f\"mv {path} {new_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952a9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
