# fortier_project
BrainHack School 2021 project

## Bio
Mr. Fortier is a Master student in Psychology at Université de Montréal.
Before that, he did a first Bachelor degree in Music writing (B. Mus.) and a second Bachelor degree in Cognitive neuroscience (B. Sc.).
Having backgrounds in both of these fields, his research interests include auditory perception, music perception and creation, and noise pollution's effects on perception and health (physical and mental).
He is currently part of the auditory perception and protection branch of the Projet Courtois NeuroMod (Centre de recherche de l'Institut universitaire de gériatrie de Montréal).

<a href="https://github.com/eddyfortier">
   <img src="https://avatars.githubusercontent.com/u/72314243?v=4" width="100px;" alt=""/>
   <br /><sub><b>Eddy Fortier</b></sub>
</a>

## Project background
The Projet Courtois NeuroMod is a longitudinal fMRI data acquisition project where participants get scanned almost every week.
One risk associated with intensives protocols like this one is the chronic exposure of the participants to high noise levels during the scan sessions.
This is why it is important to regularly monitor their auditory health to ensure that the research protocol is not causing any damage to the participants' hearing.
Part of the auditory perception's job is to do this monitoring task.
To do so, the participants go through different clinical tests every month to keep track of the evolution of their auditory health.
Some of those test data, such as the pure-tone audiometry test data, are more easily interpreted when rendered into graphic displays.
But with these repeated test comes important amount of data to process, and in order to do that efficiently, an automated graph generation pipeline might be a better option than to manually generate each of them.

![P01-Baseline 2, Bilateral.png](images/P01-Baseline_2_Bilateral.png)

Another task that could be interesting to do could be to try and use these test data to try and fingerprint the participant based on their results to the tests.
Since every person's hearing is unique and is affected by the individual auditory experience, it could be interesting to try that kind of machine learning classification task.

## Tools
The plan is to use the following tools from the BrainHack School's tutorials in this project:
- Git and GitHub for the collaborative work and the version control of the project
- Python scripts to execute the tasks
- The Bash terminal environment to work on the scripts and run them.
- Markdown to build this README.md file
- Plotting libraries such as Matplotlib, Seaborn or Plotly
- Machine learning libraries for the fingerprinting task
